view(mtcars)
View(mtcars)
install.packages("psych")
library("psych", lib.loc="~/R/win-library/3.4")
describe(mtcars)
install.packages("lme4")
install.packages(c("latticeDensity", "regress"))
View(mtcars)
summary(mtcars)
install.packages("car")
library("car", lib.loc="~/R/win-library/3.4")
some(store.df)
install.packages("boxplot")
install.packages("boxplotdbl")
install.packages(c("sp", "spam"))
y <- rnorm(100)
boxplot(y)
identify(rep(1,length(y)),y,labels = seq_along(y))
summary(x)
summary(y)
boxplot.stats(x)$out
boxplot.stats(y)$out
boxplot.stats(y)
boxplot(mpg~cyl,data=mtcars, xlab="Cylinders", ylab="MPG"
boxplot(mpg~cyl,data=mtcars, xlab="Cylinders", ylab="MPG"
)
boxplot(disp~vs,data=mtcars, xlab="Cylinders", ylab="MPG")
boxplot(disp~cyl,data=mtcars, xlab="Cylinders", ylab="MPG")
install.packages("apriori")
install.packages("DMwR")
boxplot(disp~cyl,data=mtcars, xlab="Cylinders", ylab="MPG")
apriori(data, parameter = NULL, appearance = NULL, control = NULL)
install.packages("arules")
install.packages("TraMineR")
library("TraMineR", lib.loc="~/R/win-library/3.4")
install.packages(c("car", "spam", "xts"))
library("TraMineR", lib.loc="~/R/win-library/3.4")
data(mvad)
install.packages("TraMineR")
library("TraMinerR")
library("TraMineR")
data(mvad)
install.packages("TraMineRextras")
library("TraMineR", lib.loc="~/R/win-library/3.4")
library("TraMineRextras", lib.loc="~/R/win-library/3.4")
data(mvad)
detach("package:TraMineRextras", unload=TRUE)
detach("package:TraMineR", unload=TRUE)
library("TraMineR", lib.loc="~/R/win-library/3.4")
install.packages("acepack")
library("TraMineR", lib.loc="~/R/win-library/3.4")
data(mvad)
summary(mvad)
myseq <- seqdef(mvad,17:86)
seqiplot(myseq)
seqfplot(myseq)
table(mvad)
setwd("C:/Users/Harsh Mishra/Desktop/intership")
setwd("C:/Users/Harsh Mishra/Desktop/intership")
require(twitteR)
require(RCurl)
consumer_key <- 'wTK1H3S6vpkVZvqpW8kwrkX2e'
consumer_secret <- 'G2hFntcVniy1Xvdl2eO8sHzaBDjTtRhuKjepF9Scq3xRtV8kqW'
access_token <- '2311801518-cuFKlOfmmkUtJ0YZRycq2euSNPFMbrQcbfE8MUi'
access_secret <- 'K9feLxFO19jFx08JJbE0jCDngmuYhzMj3F6KuUCDOUx79'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
require(wordcloud)
require(tm)
help("searchTwitter")
ono <- searchTwitter('onomah'+'villa', lang = "en", since = 2017-08-05,until = 2017-08-06)
ono <- searchTwitter("onomah"+ "villa", lang = "en", since = "2017-08-05",until = "2017-08-06")
ono <- searchTwitter("onomah + villa", lang = "en", since = "2017-08-05",until = "2017-08-06")
ono_text <- sapply(ono, function(x) x$getText())
spurs_corpus <- Corpus(VectorSource(ono_text))
spurs_clean <- tm_map(spurs_corpus,removePunctuation)
spurs_clean <- tm_map(spurs_clean,content_transformer(tolower))
spurs_clean <- tm_map(spurs_clean,removeWords,stopwords("english"))
spurs_clean <- tm_map(spurs_clean,removeNumbers)
spurs_clean <- tm_map(spurs_clean,stripWhitespace)
wordcloud(spurs_clean)
spurs_clean <- tm_map(spurs_clean,removeWords,c("onomah")
)
wordcloud(spurs_clean)
ono <- searchTwitter("onomah + villa", lang = "en", n = 1000, resultType = "recent")
ono_text <- sapply(ono, function(x) x$getText())
spurs_corpus <- Corpus(VectorSource(ono_text))
spurs_clean <- tm_map(spurs_corpus,removePunctuation)
spurs_clean <- tm_map(spurs_clean,content_transformer(tolower))
spurs_clean <- tm_map(spurs_clean,removeWords,stopwords("english"))
spurs_clean <- tm_map(spurs_clean,removeNumbers)
spurs_clean <- tm_map(spurs_clean,stripWhitespace)
wordcloud(spurs_clean)
spurs_clean <- tm_map(spurs_clean,removeWords,c("josh"))
wordcloud(spurs_clean)
ono <- searchTwitter("onomah + villa", lang = "en", n = 500, resultType = "recent")
ono_text <- sapply(ono, function(x) x$getText())
spurs_corpus <- Corpus(VectorSource(ono_text))
spurs_clean <- tm_map(spurs_corpus,removePunctuation)
spurs_clean <- tm_map(spurs_clean,content_transformer(tolower))
spurs_clean <- tm_map(spurs_clean,removeWords,stopwords("english"))
spurs_clean <- tm_map(spurs_clean,removeNumbers)
spurs_clean <- tm_map(spurs_clean,stripWhitespace)
wordcloud(spurs_clean)
spurs_clean <- tm_map(spurs_clean,removeWords,c("villa","josh","loan","seasonlong"))
wordcloud(spurs_clean)
spurs_clean <- tm_map(spurs_clean,removeWords,c("villa","josh","loan","seasonlong","aston","tottenham"))
wordcloud(spurs_clean,random.order = F,colors = rainbow(50))
wordcloud(spurs_clean,random.order = F)
ono <- searchTwitter("onomah + villa", lang = "en", n = 100, resultType = "mostrecent")
ono_text <- sapply(ono, function(x) x$getText())
spurs_corpus <- Corpus(VectorSource(ono_text))
spurs_clean <- tm_map(spurs_corpus,removePunctuation)
spurs_clean <- tm_map(spurs_clean,content_transformer(tolower))
spurs_clean <- tm_map(spurs_clean,removeWords,stopwords("english"))
spurs_clean <- tm_map(spurs_clean,removeNumbers)
spurs_clean <- tm_map(spurs_clean,stripWhitespace)
spurs_clean <- tm_map(spurs_clean,removeWords,c("villa","josh","loan","seasonlong","aston","tottenham","onomah"))
wordcloud(spurs_clean,random.order = F)
spurs_clean <- tm_map(spurs_clean,removeWords,c("villa","josh","loan","seasonlong","aston","tottenham","onomah","joined","avfc","deal","done"))
wordcloud(spurs_clean,random.order = F)
wordcloud(spurs_clean,random.order = T)
wordcloud(spurs_clean,random.order = F,scale = c(3,0.5))
wordcloud(spurs_clean,random.order = F,scale = c(3,1))
wordcloud(spurs_clean,random.order = F,scale = c(3,0.4))
wordcloud(spurs_clean,random.order = F,scale = c(5,1))
wordcloud(spurs_clean,random.order = F,scale = c(2,0.2))
spurs_clean <- tm_map(spurs_clean,removeWords,c("villa","josh","loan","seasonlong","aston","tottenham","onomah","joined","avfc","deal","done","deadlinedaylive","source","avfcofficial"))
wordcloud(spurs_clean,random.order = F,scale = c(2,0.2))
ono <- searchTwitter("sissoko + spurs", lang = "en", n = 500, resultType = "mostrecent")
ono_text <- sapply(ono, function(x) x$getText())
spurs_corpus <- Corpus(VectorSource(ono_text))
spurs_clean <- tm_map(spurs_corpus,removePunctuation)
spurs_clean <- tm_map(spurs_clean,content_transformer(tolower))
spurs_clean <- tm_map(spurs_clean,removeWords,stopwords("english"))
spurs_clean <- tm_map(spurs_clean,removeNumbers)
spurs_clean <- tm_map(spurs_clean,stripWhitespace)
spurs_clean <- tm_map(spurs_clean,removeWords,c("sissoko","spurs"))
wordcloud(spurs_clean,random.order = F,scale = c(2,0.2))
ono <- searchTwitter("#coys", lang = "en", n = 500, resultType = "mostrecent")
ono_text <- sapply(ono, function(x) x$getText())
spurs_corpus <- Corpus(VectorSource(ono_text))
spurs_clean <- tm_map(spurs_corpus,removePunctuation)
spurs_clean <- tm_map(spurs_clean,content_transformer(tolower))
spurs_clean <- tm_map(spurs_clean,removeWords,stopwords("english"))
spurs_clean <- tm_map(spurs_clean,removeNumbers)
spurs_clean <- tm_map(spurs_clean,stripWhitespace)
spurs_clean <- tm_map(spurs_clean,removeWords,c("#coys"))
wordcloud(spurs_clean,random.order = F,scale = c(2,0.2))
spurs_clean <- tm_map(spurs_clean,removeWords,c("#coys","coys"))
wordcloud(spurs_clean,random.order = F,scale = c(2,0.2))
spurs_clean <- tm_map(spurs_clean,removeWords,c("#coys","coys","spursofficial"))
wordcloud(spurs_clean,random.order = F,scale = c(2,0.2), colors = rainbow(50))
wordcloud(spurs_clean,random.order = F,scale = c(4,0.5), colors = rainbow(50))
require(twitteR)
require(RCurl)
consumer_key <- 'wTK1H3S6vpkVZvqpW8kwrkX2e'
consumer_secret <- 'G2hFntcVniy1Xvdl2eO8sHzaBDjTtRhuKjepF9Scq3xRtV8kqW'
access_token <- '2311801518-cuFKlOfmmkUtJ0YZRycq2euSNPFMbrQcbfE8MUi'
access_secret <- 'K9feLxFO19jFx08JJbE0jCDngmuYhzMj3F6KuUCDOUx79'
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
spurs <- searchTwitter('first signing + spurs + thfc', n=100, lang = "en", resultType ="recent")
spurs <- searchTwitter('first signing + spurs + thfc', n=100, lang = "en")
spurs <- searchTwitter('first signing + spurs', n=100, lang = "en")
spurs <- searchTwitter('first signing + spurs', n=1000, lang = "en")
spurs_text <- sapply(spurs, function(x) x$getText())
spurs_corpus <- Corpus(VectorSource(spurs_text))
spurs_clean <- tm_map(spurs_corpus,removePunctuation)
spurs_clean <- tm_map(spurs_clean,content_transformer(tolower))
spurs_clean <- tm_map(spurs_clean,removeWords,stopwords("english"))
spurs_clean <- tm_map(spurs_clean,removeNumbers)
spurs_clean <- tm_map(spurs_clean,stripWhitespace)
require(tm)
require(wordcloud)
spurs_text <- sapply(spurs, function(x) x$getText())
spurs_corpus <- Corpus(VectorSource(spurs_text))
spurs_clean <- tm_map(spurs_corpus,removePunctuation)
spurs_clean <- tm_map(spurs_clean,content_transformer(tolower))
spurs_clean <- tm_map(spurs_clean,removeWords,stopwords("english"))
spurs_clean <- tm_map(spurs_clean,removeNumbers)
spurs_clean <- tm_map(spurs_clean,stripWhitespace)
wordcloud(spurs_clean)
barplot(head((data$highjump),3),names.arg=head(data$X,3),xlab="Athletes")
q()
load("C:/Users/Harsh Mishra/Desktop/5th sem/da/.RData")
png(file="bar_hurdles.png")
barplot(head((1/data$hurdles),3),names.arg=head(data$X,3),xlab="Athletes")
barplot(head((data$highjump),3),names.arg=head(data$X,3),xlab="Athletes")
View(data)
barplot(head((data$highjump),3),names.arg=head(data$X,3),xlab="Athletes")
barplot(head((data$highjump),3),names.arg=head(data$X,3),xlab="Athletes")
View(data)
boxplot(data)
boxplot(data$run800m)
datan <- data[-c(8)]
View(datan)
datan <- data[-c(8),]
datan <- data[-c(15),]
library(ggplot2)
ggplot(datan, aes(datan$hurdles, datan$shot, color = Species)) + geom_point()
ggplot(datan, aes(datan$hurdles, datan$shot, color = datan$score)) + geom_point()
set.seed(20)
View(data)
View(datan)
Cluster <- kmeans(datan[,4:8],2,nstart = 20)
Cluster
Cluster <- kmeans(datan[,2:8],2,nstart = 20)
Cluster
names <- [Greiner,Ruotsalainen]
names <- (Greiner,Ruotsalainen)
names <- ("Greiner","Ruotsalainen")
table(Cluster$cluster)
dataf <- cbind(data[8])
dataf
dataf <- cbind(data[,8])
dataf
Cluster$size
datan <- data[-c(8),]
datan <- datan[-c(15),]
View(datan)
set.seed(20)
Cluster <- kmeans(datan[,2:8],2,nstart = 20)
table(Cluster$cluster)
Cluster$centers
Cluster <- kmeans(datan[,2:8],3,nstart = 20)
Cluster
Cluster <- kmeans(datan[,2:9],3,nstart = 20)
Cluster
Cluster$totss
Cluster$iter
Cluster <- kmeans(datan[,2:9],4,nstart = 20)
Cluster
setwd("C:/Users/Harsh Mishra/Desktop/bigdata/python")
setwd("C:/Users/Harsh Mishra/Desktop/big data/python")
iostat <- read.csv("iostat_result.csv")
iostat <- read.csv("iostat_result50mb.csv")
View(iostat)
reg <- cbind(iostat[7,9,10,13])
reg <- cbind(iostat[7:13])
View(reg)
iostat <- iostat[,-c(2)]
View(reg)
reg1 <- reg[,-c(2)]
View(reg1)
reg1 <- reg1[,-c(4)]
reg1 <- reg1[,-c(5)]
reg1 <- reg[,-c(2)]
reg1 <- reg1[,-c(4)]
reg1 <- reg1[,-c(4)]
reg50mb <- reg1
View(reg50mb)
iostat <- read.csv("iostat_result100mb.csv")
reg100 <- cbind(iostat[7:13])
reg100 <- reg100[,-c(2)]
View(reg100mb)
View(reg100)
reg100 <- reg100[,-c(4)]
reg100 <- reg100[,-c(4)]
View(reg100)
iostat <- read.csv("iostat_result300mb.csv")
reg300 <- cbind(iostat[7:13])
reg300 <- reg300[,-c(2)]
View(reg300)
reg300 <- reg300[,-c(4)]
reg300 <- reg300[,-c(4)]
iostat <- read.csv("iostat_result600mb.csv")
reg600 <- cbind(iostat[7:13])
reg600 <- reg600[,-c(2)]
View(reg600)
reg600 <- reg600[,-c(4)]
reg600 <- reg600[,-c(4)]
iostat <- read.csv("iostat_result2gb.csv")
reg2gb <- cbind(iostat[7:13])
reg2gb <- reg2gb[,-c(2)]
View(reg2gb)
reg2gb <- reg2gb[,-c(4)]
reg2gb <- reg2gb[,-c(4)]
+
-+
dwqa
par(mfrow=c(2,3))
corrplot(corr=cor(reg50mb, use="complete.obs"),
method ="ellipse",title = "50mb")
corrplot(corr=cor(reg100, use="complete.obs"),
method ="ellipse",title = "100mb")
corrplot(corr=cor(reg300, use="complete.obs"),
method ="ellipse",title = "300mb")
corrplot(corr=cor(reg600, use="complete.obs"),
method ="ellipse",title = "600mb")
corrplot(corr=cor(reg2gb, use="complete.obs"),
method ="ellipse",title = "2gb")
library(corrplot)
par(mfrow=c(2,3))
corrplot(corr=cor(reg50mb, use="complete.obs"),
method ="ellipse",title = "50mb")
corrplot(corr=cor(reg100, use="complete.obs"),
method ="ellipse",title = "100mb")
corrplot(corr=cor(reg300, use="complete.obs"),
method ="ellipse",title = "300mb")
corrplot(corr=cor(reg600, use="complete.obs"),
method ="ellipse",title = "600mb")
corrplot(corr=cor(reg2gb, use="complete.obs"),
method ="ellipse",title = "2gb")
iostat <- read.csv("iostat_result5gb.csv")
reg5gb <- cbind(iostat[7:13])
reg5gb <- reg5gb[,-c(2)]
View(reg5gb)
reg5gb <- reg5gb[,-c(4)]
reg5gb <- reg5gb[,-c(4)]
corrplot(corr=cor(reg2gb, use="complete.obs"),method ="ellipse",title = "5gb")
